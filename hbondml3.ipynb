{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "enhanced-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "polish-drawing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acid</th>\n",
       "      <th>Base</th>\n",
       "      <th>Agroup</th>\n",
       "      <th>Aeneg</th>\n",
       "      <th>Asize</th>\n",
       "      <th>Beneg</th>\n",
       "      <th>Bsize</th>\n",
       "      <th>Δν</th>\n",
       "      <th>-ΔH (kJ mol-1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CCl3)2CHOH</td>\n",
       "      <td>Acetonitrile</td>\n",
       "      <td>COH</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150</td>\n",
       "      <td>2.90</td>\n",
       "      <td>166.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>22.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CH2Cl)2CHOH</td>\n",
       "      <td>Acetonitrile</td>\n",
       "      <td>COH</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150</td>\n",
       "      <td>2.90</td>\n",
       "      <td>166.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>14.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(CHCl2)2CHOH</td>\n",
       "      <td>Acetonitrile</td>\n",
       "      <td>COH</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150</td>\n",
       "      <td>2.90</td>\n",
       "      <td>166.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acetic acid</td>\n",
       "      <td>Pyridine</td>\n",
       "      <td>COOH</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150</td>\n",
       "      <td>2.90</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acetic acid</td>\n",
       "      <td>Dimethyl sulfoxide</td>\n",
       "      <td>COOH</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>33.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Acid                Base Agroup  Aeneg  Asize  Beneg  Bsize  \\\n",
       "0   (CCl3)2CHOH        Acetonitrile    COH   3.41    150   2.90  166.0   \n",
       "1  (CH2Cl)2CHOH        Acetonitrile    COH   3.41    150   2.90  166.0   \n",
       "2  (CHCl2)2CHOH        Acetonitrile    COH   3.41    150   2.90  166.0   \n",
       "3   Acetic acid            Pyridine   COOH   3.41    150   2.90  166.0   \n",
       "4   Acetic acid  Dimethyl sulfoxide   COOH   3.41    150   3.41  150.0   \n",
       "\n",
       "       Δν  -ΔH (kJ mol-1)  \n",
       "0   211.0            22.6  \n",
       "1   102.0            14.2  \n",
       "2   174.0            19.8  \n",
       "3  1000.0            40.0  \n",
       "4   840.0            33.5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "DATA_FILENAME = \"hbonddata.xlsx\"\n",
    "dataframe_raw = pd.read_excel(DATA_FILENAME,sheet_name='data')\n",
    "dataframe_raw = dataframe_raw.filter(items=['Acid', 'Base', 'Agroup', 'Aeneg', 'Asize', 'Beneg', 'Bsize', 'Δν', '-ΔH (kJ mol-1)'])\n",
    "# Drop the rows with NANs. \n",
    "dataframe_raw = dataframe_raw.dropna(axis=0, how = 'any')\n",
    "dataframe_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sized-daily",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acid</th>\n",
       "      <th>Base</th>\n",
       "      <th>Agroup</th>\n",
       "      <th>Aeneg</th>\n",
       "      <th>Asize</th>\n",
       "      <th>Beneg</th>\n",
       "      <th>Bsize</th>\n",
       "      <th>Δν</th>\n",
       "      <th>ΔH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(CCl3)2CHOH</td>\n",
       "      <td>Acetonitrile</td>\n",
       "      <td>COH</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150</td>\n",
       "      <td>2.90</td>\n",
       "      <td>166.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>22.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CH2Cl)2CHOH</td>\n",
       "      <td>Acetonitrile</td>\n",
       "      <td>COH</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150</td>\n",
       "      <td>2.90</td>\n",
       "      <td>166.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>14.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(CHCl2)2CHOH</td>\n",
       "      <td>Acetonitrile</td>\n",
       "      <td>COH</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150</td>\n",
       "      <td>2.90</td>\n",
       "      <td>166.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acetic acid</td>\n",
       "      <td>Pyridine</td>\n",
       "      <td>COOH</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150</td>\n",
       "      <td>2.90</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acetic acid</td>\n",
       "      <td>Dimethyl sulfoxide</td>\n",
       "      <td>COOH</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>33.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Acid                Base Agroup  Aeneg  Asize  Beneg  Bsize  \\\n",
       "0   (CCl3)2CHOH        Acetonitrile    COH   3.41    150   2.90  166.0   \n",
       "1  (CH2Cl)2CHOH        Acetonitrile    COH   3.41    150   2.90  166.0   \n",
       "2  (CHCl2)2CHOH        Acetonitrile    COH   3.41    150   2.90  166.0   \n",
       "3   Acetic acid            Pyridine   COOH   3.41    150   2.90  166.0   \n",
       "4   Acetic acid  Dimethyl sulfoxide   COOH   3.41    150   3.41  150.0   \n",
       "\n",
       "       Δν    ΔH  \n",
       "0   211.0  22.6  \n",
       "1   102.0  14.2  \n",
       "2   174.0  19.8  \n",
       "3  1000.0  40.0  \n",
       "4   840.0  33.5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the columns\n",
    "dataframe_raw.rename(columns={'-ΔH (kJ mol-1)': 'ΔH'}, inplace =True)\n",
    "dataframe_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "executive-symbol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aeneg</th>\n",
       "      <th>Asize</th>\n",
       "      <th>Beneg</th>\n",
       "      <th>Bsize</th>\n",
       "      <th>Δν</th>\n",
       "      <th>ΔH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>318.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>318.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.238428</td>\n",
       "      <td>155.789308</td>\n",
       "      <td>3.172390</td>\n",
       "      <td>157.122642</td>\n",
       "      <td>317.967614</td>\n",
       "      <td>19.464534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.325150</td>\n",
       "      <td>10.909563</td>\n",
       "      <td>0.303832</td>\n",
       "      <td>8.586949</td>\n",
       "      <td>350.151747</td>\n",
       "      <td>11.840464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.480000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>2.040000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.410000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>109.192487</td>\n",
       "      <td>10.632760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.410000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>3.410000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>218.741953</td>\n",
       "      <td>17.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.410000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>3.410000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>364.500000</td>\n",
       "      <td>25.104000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.410000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>3.410000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>2300.000000</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Aeneg       Asize       Beneg       Bsize           Δν          ΔH\n",
       "count  318.000000  318.000000  318.000000  318.000000   318.000000  318.000000\n",
       "mean     3.238428  155.789308    3.172390  157.122642   317.967614   19.464534\n",
       "std      0.325150   10.909563    0.303832    8.586949   350.151747   11.840464\n",
       "min      2.480000  150.000000    2.040000  150.000000     1.000000    0.700000\n",
       "25%      3.410000  150.000000    2.900000  150.000000   109.192487   10.632760\n",
       "50%      3.410000  150.000000    3.410000  150.000000   218.741953   17.600000\n",
       "75%      3.410000  150.000000    3.410000  166.000000   364.500000   25.104000\n",
       "max      3.410000  189.000000    3.410000  177.000000  2300.000000   67.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the info of the data\n",
    "dataframe_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "combined-alcohol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agroup</th>\n",
       "      <th>Aeneg</th>\n",
       "      <th>Asize</th>\n",
       "      <th>Beneg</th>\n",
       "      <th>Bsize</th>\n",
       "      <th>Δν</th>\n",
       "      <th>ΔH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>COH</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150.0</td>\n",
       "      <td>117.160000</td>\n",
       "      <td>12.177000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>COH</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150</td>\n",
       "      <td>2.90</td>\n",
       "      <td>166.0</td>\n",
       "      <td>280.720000</td>\n",
       "      <td>12.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>HOH</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150</td>\n",
       "      <td>2.90</td>\n",
       "      <td>166.0</td>\n",
       "      <td>480.240000</td>\n",
       "      <td>32.076000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>NH</td>\n",
       "      <td>2.90</td>\n",
       "      <td>166</td>\n",
       "      <td>2.90</td>\n",
       "      <td>166.0</td>\n",
       "      <td>498.800000</td>\n",
       "      <td>24.453000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>PhOH</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150.0</td>\n",
       "      <td>138.955647</td>\n",
       "      <td>17.355650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>COH</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150</td>\n",
       "      <td>2.90</td>\n",
       "      <td>166.0</td>\n",
       "      <td>421.080000</td>\n",
       "      <td>26.532000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>PhOH</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150</td>\n",
       "      <td>2.90</td>\n",
       "      <td>166.0</td>\n",
       "      <td>951.200000</td>\n",
       "      <td>37.719000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>COH</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150</td>\n",
       "      <td>2.90</td>\n",
       "      <td>166.0</td>\n",
       "      <td>350.260170</td>\n",
       "      <td>17.024278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>PhOH</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150.0</td>\n",
       "      <td>392.080000</td>\n",
       "      <td>33.165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>PhOH</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150</td>\n",
       "      <td>3.41</td>\n",
       "      <td>150.0</td>\n",
       "      <td>444.280000</td>\n",
       "      <td>28.413000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Agroup  Aeneg  Asize  Beneg  Bsize          Δν         ΔH\n",
       "266    COH   3.41    150   3.41  150.0  117.160000  12.177000\n",
       "79     COH   3.41    150   2.90  166.0  280.720000  12.870000\n",
       "324    HOH   3.41    150   2.90  166.0  480.240000  32.076000\n",
       "241     NH   2.90    166   2.90  166.0  498.800000  24.453000\n",
       "156   PhOH   3.41    150   3.41  150.0  138.955647  17.355650\n",
       "..     ...    ...    ...    ...    ...         ...        ...\n",
       "171    COH   3.41    150   2.90  166.0  421.080000  26.532000\n",
       "172   PhOH   3.41    150   2.90  166.0  951.200000  37.719000\n",
       "92     COH   3.41    150   2.90  166.0  350.260170  17.024278\n",
       "67    PhOH   3.41    150   3.41  150.0  392.080000  33.165000\n",
       "182   PhOH   3.41    150   3.41  150.0  444.280000  28.413000\n",
       "\n",
       "[270 rows x 7 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "your_name = \"Stcike sarpherise Lei h bond project\" # at least 5 characters\n",
    "def customize_dataset(dataframe_raw, rand_str):\n",
    "    dataframe = dataframe_raw.copy(deep=True)\n",
    "    # drop some rows\n",
    "    dataframe = dataframe.sample(int(0.85*len(dataframe)), random_state=int(ord(rand_str[0])))\n",
    "    # scale input\n",
    "    dataframe.Δν = dataframe.Δν * ord(rand_str[1])/100.\n",
    "    # scale target\n",
    "    dataframe.ΔH = dataframe.ΔH * ord(rand_str[2])/100.\n",
    "    # drop column\n",
    "    if ord(rand_str[3]) % 2 == 1:\n",
    "        dataframe = dataframe.drop(['Acid','Base'], axis=1)\n",
    "    return dataframe\n",
    "\n",
    "dataframe = customize_dataset(dataframe_raw, your_name)\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "greenhouse-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = ['Aeneg', 'Asize', 'Beneg', 'Bsize', 'Δν']\n",
    "categorical_cols = ['Agroup']\n",
    "output_cols = ['ΔH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "particular-senator",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  3.41      , 150.        ,   3.41      , 150.        ,\n",
       "         117.16      ],\n",
       "        [  3.41      , 150.        ,   2.9       , 166.        ,\n",
       "         280.72      ],\n",
       "        [  3.41      , 150.        ,   2.9       , 166.        ,\n",
       "         480.24      ],\n",
       "        ...,\n",
       "        [  3.41      , 150.        ,   2.9       , 166.        ,\n",
       "         350.26016967],\n",
       "        [  3.41      , 150.        ,   3.41      , 150.        ,\n",
       "         392.08      ],\n",
       "        [  3.41      , 150.        ,   3.41      , 150.        ,\n",
       "         444.28      ]]),\n",
       " array([[12.177    ],\n",
       "        [12.87     ],\n",
       "        [32.076    ],\n",
       "        [24.453    ],\n",
       "        [17.3556504],\n",
       "        [ 4.158    ],\n",
       "        [13.3791768],\n",
       "        [40.593168 ],\n",
       "        [ 6.633    ],\n",
       "        [14.49756  ],\n",
       "        [39.35052  ],\n",
       "        [ 7.92     ],\n",
       "        [12.7992744],\n",
       "        [45.149544 ],\n",
       "        [12.1779504],\n",
       "        [38.107872 ],\n",
       "        [43.906896 ],\n",
       "        [31.0662   ],\n",
       "        [14.949    ],\n",
       "        [15.4088352],\n",
       "        [ 8.91     ],\n",
       "        [21.0421728],\n",
       "        [19.3853088],\n",
       "        [19.468152 ],\n",
       "        [13.0063824],\n",
       "        [30.69     ],\n",
       "        [ 9.108    ],\n",
       "        [35.64     ],\n",
       "        [22.374    ],\n",
       "        [24.849    ],\n",
       "        [32.769    ],\n",
       "        [15.741    ],\n",
       "        [ 7.029    ],\n",
       "        [ 4.059    ],\n",
       "        [11.0595672],\n",
       "        [ 2.079    ],\n",
       "        [13.2134904],\n",
       "        [15.6159432],\n",
       "        [ 9.108    ],\n",
       "        [33.13728  ],\n",
       "        [19.305    ],\n",
       "        [23.76     ],\n",
       "        [15.2431488],\n",
       "        [12.4679016],\n",
       "        [20.295    ],\n",
       "        [ 7.524    ],\n",
       "        [ 9.941184 ],\n",
       "        [ 6.237    ],\n",
       "        [ 4.653    ],\n",
       "        [10.791    ],\n",
       "        [23.859    ],\n",
       "        [21.539232 ],\n",
       "        [37.6108128],\n",
       "        [24.85296  ],\n",
       "        [27.72     ],\n",
       "        [ 2.97     ],\n",
       "        [20.691    ],\n",
       "        [10.8938808],\n",
       "        [34.794144 ],\n",
       "        [11.598048 ],\n",
       "        [15.642    ],\n",
       "        [20.295    ],\n",
       "        [16.982856 ],\n",
       "        [ 6.336    ],\n",
       "        [23.166    ],\n",
       "        [ 7.524    ],\n",
       "        [21.978    ],\n",
       "        [ 1.782    ],\n",
       "        [18.216    ],\n",
       "        [33.13728  ],\n",
       "        [12.078    ],\n",
       "        [25.245    ],\n",
       "        [19.998    ],\n",
       "        [19.701    ],\n",
       "        [28.6223256],\n",
       "        [ 4.653    ],\n",
       "        [22.176    ],\n",
       "        [17.424    ],\n",
       "        [ 6.633    ],\n",
       "        [14.85     ],\n",
       "        [35.4568896],\n",
       "        [11.598048 ],\n",
       "        [40.59     ],\n",
       "        [19.0953576],\n",
       "        [ 8.91     ],\n",
       "        [21.953448 ],\n",
       "        [18.315    ],\n",
       "        [21.78     ],\n",
       "        [24.438744 ],\n",
       "        [ 4.752    ],\n",
       "        [15.345    ],\n",
       "        [20.394    ],\n",
       "        [39.303    ],\n",
       "        [15.345    ],\n",
       "        [33.561    ],\n",
       "        [25.344    ],\n",
       "        [32.868    ],\n",
       "        [15.543    ],\n",
       "        [18.225504 ],\n",
       "        [20.1723192],\n",
       "        [ 3.168    ],\n",
       "        [13.266    ],\n",
       "        [13.2134904],\n",
       "        [16.533    ],\n",
       "        [ 8.118    ],\n",
       "        [25.245    ],\n",
       "        [19.882368 ],\n",
       "        [31.086    ],\n",
       "        [27.338256 ],\n",
       "        [ 7.821    ],\n",
       "        [19.602    ],\n",
       "        [15.741    ],\n",
       "        [17.127    ],\n",
       "        [ 7.425    ],\n",
       "        [20.295    ],\n",
       "        [35.64     ],\n",
       "        [ 9.504    ],\n",
       "        [17.82     ],\n",
       "        [36.432    ],\n",
       "        [65.34     ],\n",
       "        [43.56     ],\n",
       "        [14.949    ],\n",
       "        [20.4208488],\n",
       "        [ 4.554    ],\n",
       "        [22.275    ],\n",
       "        [22.9061448],\n",
       "        [45.56376  ],\n",
       "        [ 9.9      ],\n",
       "        [22.374    ],\n",
       "        [18.216    ],\n",
       "        [ 8.217    ],\n",
       "        [16.137    ],\n",
       "        [14.704668 ],\n",
       "        [ 4.95     ],\n",
       "        [16.236    ],\n",
       "        [29.898    ],\n",
       "        [44.55     ],\n",
       "        [41.58     ],\n",
       "        [12.87     ],\n",
       "        [43.906896 ],\n",
       "        [21.74634  ],\n",
       "        [26.92404  ],\n",
       "        [15.741    ],\n",
       "        [12.177    ],\n",
       "        [30.03066  ],\n",
       "        [13.266    ],\n",
       "        [10.989    ],\n",
       "        [16.0715808],\n",
       "        [20.1308976],\n",
       "        [30.651984 ],\n",
       "        [30.69     ],\n",
       "        [16.929    ],\n",
       "        [ 5.841    ],\n",
       "        [29.7      ],\n",
       "        [57.42     ],\n",
       "        [19.008    ],\n",
       "        [29.403    ],\n",
       "        [22.2433992],\n",
       "        [17.424    ],\n",
       "        [ 7.92     ],\n",
       "        [14.3318736],\n",
       "        [30.393    ],\n",
       "        [ 8.118    ],\n",
       "        [17.5213368],\n",
       "        [35.046    ],\n",
       "        [19.468152 ],\n",
       "        [ 7.623    ],\n",
       "        [33.165    ],\n",
       "        [17.424    ],\n",
       "        [ 6.039    ],\n",
       "        [ 3.564    ],\n",
       "        [ 9.504    ],\n",
       "        [36.63     ],\n",
       "        [38.61     ],\n",
       "        [17.82     ],\n",
       "        [16.2372672],\n",
       "        [35.64     ],\n",
       "        [ 9.504    ],\n",
       "        [36.451008 ],\n",
       "        [28.580904 ],\n",
       "        [17.1485424],\n",
       "        [ 9.108    ],\n",
       "        [ 6.633    ],\n",
       "        [14.256    ],\n",
       "        [22.78188  ],\n",
       "        [21.9120264],\n",
       "        [10.395    ],\n",
       "        [17.397072 ],\n",
       "        [24.75     ],\n",
       "        [ 9.9      ],\n",
       "        [11.187    ],\n",
       "        [18.513    ],\n",
       "        [ 7.029    ],\n",
       "        [21.953448 ],\n",
       "        [14.058    ],\n",
       "        [11.187    ],\n",
       "        [41.4216   ],\n",
       "        [ 9.9      ],\n",
       "        [20.7108   ],\n",
       "        [18.63972  ],\n",
       "        [19.206    ],\n",
       "        [10.1897136],\n",
       "        [ 1.584    ],\n",
       "        [20.4208488],\n",
       "        [17.424    ],\n",
       "        [15.9058944],\n",
       "        [24.453    ],\n",
       "        [18.612    ],\n",
       "        [ 8.217    ],\n",
       "        [12.0951072],\n",
       "        [ 7.9529472],\n",
       "        [20.7108   ],\n",
       "        [28.116    ],\n",
       "        [28.99512  ],\n",
       "        [22.367664 ],\n",
       "        [ 0.693    ],\n",
       "        [43.56     ],\n",
       "        [12.7992744],\n",
       "        [20.4208488],\n",
       "        [ 6.237    ],\n",
       "        [12.1779504],\n",
       "        [10.89     ],\n",
       "        [22.572    ],\n",
       "        [35.64     ],\n",
       "        [ 2.07108  ],\n",
       "        [ 4.95     ],\n",
       "        [13.266    ],\n",
       "        [13.5034416],\n",
       "        [39.35052  ],\n",
       "        [18.612    ],\n",
       "        [ 7.92     ],\n",
       "        [17.811288 ],\n",
       "        [39.6      ],\n",
       "        [20.7108   ],\n",
       "        [15.246    ],\n",
       "        [29.1193848],\n",
       "        [16.982856 ],\n",
       "        [15.9887376],\n",
       "        [22.374    ],\n",
       "        [ 8.9884872],\n",
       "        [10.8938808],\n",
       "        [11.979    ],\n",
       "        [ 9.405    ],\n",
       "        [24.948    ],\n",
       "        [26.73     ],\n",
       "        [ 3.168    ],\n",
       "        [15.1603056],\n",
       "        [24.85296  ],\n",
       "        [ 3.663    ],\n",
       "        [31.0662   ],\n",
       "        [36.828    ],\n",
       "        [29.898    ],\n",
       "        [ 8.712    ],\n",
       "        [ 2.376    ],\n",
       "        [ 1.683    ],\n",
       "        [13.266    ],\n",
       "        [21.186    ],\n",
       "        [ 3.366    ],\n",
       "        [42.57     ],\n",
       "        [25.8056568],\n",
       "        [11.682    ],\n",
       "        [ 9.941184 ],\n",
       "        [ 7.029    ],\n",
       "        [32.076    ],\n",
       "        [17.82     ],\n",
       "        [26.532    ],\n",
       "        [37.719    ],\n",
       "        [17.0242776],\n",
       "        [33.165    ],\n",
       "        [28.413    ]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dataframe_to_arrays(dataframe):\n",
    "    # Make a copy of the original dataframe\n",
    "    dataframe1 = dataframe.copy(deep=True)\n",
    "    # Convert non-numeric categorical columns to numbers\n",
    "    for col in categorical_cols:\n",
    "        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n",
    "    # Extract input & outupts as numpy arrays\n",
    "    inputs_array = dataframe1[input_cols].to_numpy()\n",
    "    targets_array = dataframe1[output_cols].to_numpy()\n",
    "    return inputs_array, targets_array\n",
    "\n",
    "inputs_array, targets_array = dataframe_to_arrays(dataframe)\n",
    "inputs_array, targets_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "plastic-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.Tensor(inputs_array)\n",
    "targets = torch.Tensor(targets_array)\n",
    "\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "train_ds, val_ds = random_split(dataset, [225, 45])\n",
    "batch_size = 82\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "renewable-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "input_size = len(input_cols)\n",
    "output_size = len(output_cols)\n",
    "H = 35\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "class HbondModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#         self.linear = nn.Linear(input_size, output_size)                  # fill this (hint: use input_size & output_size defined above)\n",
    "        self.input_linear = nn.Linear(input_size, H)\n",
    "        self.middle_linear = nn.Linear(H, H)\n",
    "        self.output_linear = nn.Linear(H, output_size)\n",
    "               \n",
    "    def forward(self, xb):     \n",
    "        h_relu = self.input_linear(xb).clamp(min=0)\n",
    "        for _ in range(random.randint(0, 3)):\n",
    "            h_relu = self.middle_linear(h_relu).clamp(min=0)\n",
    "        out = self.output_linear(h_relu)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        inputs, targets = batch \n",
    "        # Generate predictions\n",
    "        out = self(inputs)          \n",
    "        # Calcuate loss\n",
    "        loss = criterion(out, targets)                         # fill this\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        # Generate predictions\n",
    "        out = self(inputs)\n",
    "        # Calculate loss\n",
    "        loss = criterion(out, targets)                           # fill this    \n",
    "        return {'val_loss': loss.detach()}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        return {'val_loss': epoch_loss.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result, num_epochs):\n",
    "        # Print result every 20th epoch\n",
    "        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n",
    "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "assisted-company",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': 4026.082763671875}\n"
     ]
    }
   ],
   "source": [
    "model = HbondModel()\n",
    "\n",
    "# Eval algorithm\n",
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "result = evaluate(model, val_loader)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "coated-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting algorithm\n",
    "def fit(epochs, lr, momentum, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr, momentum)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result, epochs)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dried-spoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 3580.0208\n",
      "Epoch [40], val_loss: 1150.6179\n",
      "Epoch [60], val_loss: 1104.2694\n",
      "Epoch [80], val_loss: 886.8676\n",
      "Epoch [90], val_loss: 812.4584\n",
      "Epoch [20], val_loss: 832.3939\n",
      "Epoch [40], val_loss: 798.4988\n",
      "Epoch [60], val_loss: 789.8549\n",
      "Epoch [80], val_loss: 718.8917\n",
      "Epoch [90], val_loss: 779.6071\n",
      "Epoch [20], val_loss: 752.1075\n",
      "Epoch [40], val_loss: 740.1486\n",
      "Epoch [60], val_loss: 705.2037\n",
      "Epoch [80], val_loss: 711.8788\n",
      "Epoch [90], val_loss: 721.3656\n",
      "Epoch [20], val_loss: 736.8622\n",
      "Epoch [40], val_loss: 710.0642\n",
      "Epoch [60], val_loss: 691.9840\n",
      "Epoch [80], val_loss: 758.1166\n",
      "Epoch [90], val_loss: 693.1184\n",
      "Epoch [20], val_loss: 726.9534\n",
      "Epoch [40], val_loss: 711.5714\n",
      "Epoch [60], val_loss: 712.4976\n",
      "Epoch [80], val_loss: 667.2184\n",
      "Epoch [90], val_loss: 729.3417\n",
      "Epoch [20], val_loss: 702.7180\n",
      "Epoch [40], val_loss: 660.2286\n",
      "Epoch [60], val_loss: 729.7037\n",
      "Epoch [80], val_loss: 701.6681\n",
      "Epoch [90], val_loss: 705.4083\n",
      "Epoch [20], val_loss: 679.2469\n",
      "Epoch [40], val_loss: 723.6345\n",
      "Epoch [60], val_loss: 682.8807\n",
      "Epoch [80], val_loss: 670.4726\n",
      "Epoch [90], val_loss: 700.0280\n",
      "Epoch [20], val_loss: 708.3476\n",
      "Epoch [40], val_loss: 691.9568\n",
      "Epoch [60], val_loss: 692.7900\n",
      "Epoch [80], val_loss: 692.8630\n",
      "Epoch [90], val_loss: 727.8967\n",
      "Epoch [20], val_loss: 677.5972\n",
      "Epoch [40], val_loss: 664.0518\n",
      "Epoch [60], val_loss: 722.5166\n",
      "Epoch [80], val_loss: 696.3787\n",
      "Epoch [90], val_loss: 731.9393\n",
      "Epoch [20], val_loss: 716.0018\n",
      "Epoch [40], val_loss: 666.2853\n",
      "Epoch [60], val_loss: 674.4397\n",
      "Epoch [80], val_loss: 669.1672\n",
      "Epoch [90], val_loss: 679.2924\n",
      "Epoch [20], val_loss: 673.4504\n",
      "Epoch [40], val_loss: 668.6263\n",
      "Epoch [60], val_loss: 712.4517\n",
      "Epoch [80], val_loss: 666.1482\n",
      "Epoch [90], val_loss: 661.9599\n",
      "Epoch [20], val_loss: 670.0768\n",
      "Epoch [40], val_loss: 762.4852\n",
      "Epoch [60], val_loss: 689.4180\n",
      "Epoch [80], val_loss: 676.0427\n",
      "Epoch [90], val_loss: 706.4409\n",
      "Epoch [20], val_loss: 677.3121\n",
      "Epoch [40], val_loss: 714.3225\n",
      "Epoch [60], val_loss: 670.4067\n",
      "Epoch [80], val_loss: 656.0214\n",
      "Epoch [90], val_loss: 722.8660\n",
      "Epoch [20], val_loss: 665.4330\n",
      "Epoch [40], val_loss: 665.9658\n",
      "Epoch [60], val_loss: 666.9030\n",
      "Epoch [80], val_loss: 717.5923\n",
      "Epoch [90], val_loss: 671.1851\n",
      "Epoch [20], val_loss: 696.3101\n",
      "Epoch [40], val_loss: 700.3425\n",
      "Epoch [60], val_loss: 689.1335\n",
      "Epoch [80], val_loss: 671.3491\n",
      "Epoch [90], val_loss: 680.0057\n",
      "Epoch [20], val_loss: 664.0894\n",
      "Epoch [40], val_loss: 654.8608\n",
      "Epoch [60], val_loss: 713.0343\n",
      "Epoch [80], val_loss: 683.3209\n",
      "Epoch [90], val_loss: 729.2060\n",
      "Epoch [20], val_loss: 727.5551\n",
      "Epoch [40], val_loss: 742.7311\n",
      "Epoch [60], val_loss: 667.7867\n",
      "Epoch [80], val_loss: 695.4100\n",
      "Epoch [90], val_loss: 665.7316\n",
      "Epoch [20], val_loss: 670.0418\n",
      "Epoch [40], val_loss: 678.6944\n",
      "Epoch [60], val_loss: 669.4510\n",
      "Epoch [80], val_loss: 719.4636\n",
      "Epoch [90], val_loss: 681.6462\n",
      "Epoch [20], val_loss: 715.5808\n",
      "Epoch [40], val_loss: 693.5408\n",
      "Epoch [60], val_loss: 676.0922\n",
      "Epoch [80], val_loss: 660.7946\n",
      "Epoch [90], val_loss: 715.9565\n",
      "Epoch [20], val_loss: 668.3664\n",
      "Epoch [40], val_loss: 661.6874\n",
      "Epoch [60], val_loss: 670.4253\n",
      "Epoch [80], val_loss: 706.9320\n",
      "Epoch [90], val_loss: 719.6713\n",
      "Epoch [20], val_loss: 704.8641\n",
      "Epoch [40], val_loss: 677.1638\n",
      "Epoch [60], val_loss: 657.0306\n",
      "Epoch [80], val_loss: 660.2701\n",
      "Epoch [90], val_loss: 672.1472\n",
      "Epoch [20], val_loss: 719.3738\n",
      "Epoch [40], val_loss: 677.6579\n",
      "Epoch [60], val_loss: 697.4257\n",
      "Epoch [80], val_loss: 676.9952\n",
      "Epoch [90], val_loss: 697.2009\n",
      "Epoch [20], val_loss: 672.7374\n",
      "Epoch [40], val_loss: 709.4856\n",
      "Epoch [60], val_loss: 688.9717\n",
      "Epoch [80], val_loss: 671.5461\n",
      "Epoch [90], val_loss: 717.7749\n",
      "Epoch [20], val_loss: 669.7854\n",
      "Epoch [40], val_loss: 676.5765\n",
      "Epoch [60], val_loss: 665.6354\n",
      "Epoch [80], val_loss: 666.0845\n",
      "Epoch [90], val_loss: 717.0291\n",
      "Epoch [20], val_loss: 675.7792\n",
      "Epoch [40], val_loss: 673.0687\n",
      "Epoch [60], val_loss: 670.4185\n",
      "Epoch [80], val_loss: 699.0074\n",
      "Epoch [90], val_loss: 689.8584\n",
      "Epoch [20], val_loss: 684.8130\n",
      "Epoch [40], val_loss: 673.4191\n",
      "Epoch [60], val_loss: 656.0526\n",
      "Epoch [80], val_loss: 708.9935\n",
      "Epoch [90], val_loss: 658.8582\n",
      "Epoch [20], val_loss: 673.2481\n",
      "Epoch [40], val_loss: 673.6344\n",
      "Epoch [60], val_loss: 691.1334\n",
      "Epoch [80], val_loss: 721.1702\n",
      "Epoch [90], val_loss: 659.4685\n",
      "Epoch [20], val_loss: 690.9866\n",
      "Epoch [40], val_loss: 707.5269\n",
      "Epoch [60], val_loss: 658.2396\n",
      "Epoch [80], val_loss: 678.1240\n",
      "Epoch [90], val_loss: 709.9672\n",
      "Epoch [20], val_loss: 664.7324\n",
      "Epoch [40], val_loss: 683.8096\n",
      "Epoch [60], val_loss: 674.5327\n",
      "Epoch [80], val_loss: 667.7961\n",
      "Epoch [90], val_loss: 682.6674\n",
      "Epoch [20], val_loss: 715.3580\n",
      "Epoch [40], val_loss: 683.1008\n",
      "Epoch [60], val_loss: 663.0663\n",
      "Epoch [80], val_loss: 725.7267\n",
      "Epoch [90], val_loss: 725.4861\n",
      "Epoch [20], val_loss: 722.9955\n",
      "Epoch [40], val_loss: 681.1384\n",
      "Epoch [60], val_loss: 673.0588\n",
      "Epoch [80], val_loss: 674.7623\n",
      "Epoch [90], val_loss: 713.7627\n",
      "Epoch [20], val_loss: 661.7436\n",
      "Epoch [40], val_loss: 670.1796\n",
      "Epoch [60], val_loss: 665.9184\n",
      "Epoch [80], val_loss: 669.8444\n",
      "Epoch [90], val_loss: 685.6426\n",
      "Epoch [20], val_loss: 705.2002\n",
      "Epoch [40], val_loss: 672.7265\n",
      "Epoch [60], val_loss: 696.6835\n",
      "Epoch [80], val_loss: 711.2055\n",
      "Epoch [90], val_loss: 669.0451\n",
      "Epoch [20], val_loss: 683.6280\n",
      "Epoch [40], val_loss: 667.8472\n",
      "Epoch [60], val_loss: 651.7856\n",
      "Epoch [80], val_loss: 657.5381\n",
      "Epoch [90], val_loss: 691.9186\n",
      "Epoch [20], val_loss: 654.5165\n",
      "Epoch [40], val_loss: 675.7054\n",
      "Epoch [60], val_loss: 664.8075\n",
      "Epoch [80], val_loss: 680.1605\n",
      "Epoch [90], val_loss: 684.6016\n",
      "Epoch [20], val_loss: 649.0594\n",
      "Epoch [40], val_loss: 706.0692\n",
      "Epoch [60], val_loss: 671.0870\n",
      "Epoch [80], val_loss: 734.0965\n",
      "Epoch [90], val_loss: 656.9954\n",
      "Epoch [20], val_loss: 692.7849\n",
      "Epoch [40], val_loss: 689.3438\n",
      "Epoch [60], val_loss: 655.5845\n",
      "Epoch [80], val_loss: 666.7041\n",
      "Epoch [90], val_loss: 713.3713\n",
      "Epoch [20], val_loss: 686.1062\n",
      "Epoch [40], val_loss: 719.7177\n",
      "Epoch [60], val_loss: 665.0778\n",
      "Epoch [80], val_loss: 708.0930\n",
      "Epoch [90], val_loss: 648.9611\n",
      "Epoch [20], val_loss: 707.1068\n",
      "Epoch [40], val_loss: 663.2698\n",
      "Epoch [60], val_loss: 665.1579\n",
      "Epoch [80], val_loss: 666.6323\n",
      "Epoch [90], val_loss: 710.0140\n",
      "Epoch [20], val_loss: 678.4351\n",
      "Epoch [40], val_loss: 660.7963\n",
      "Epoch [60], val_loss: 666.3926\n",
      "Epoch [80], val_loss: 694.3104\n",
      "Epoch [90], val_loss: 671.7784\n",
      "Epoch [20], val_loss: 682.2979\n",
      "Epoch [40], val_loss: 708.2228\n",
      "Epoch [60], val_loss: 735.0515\n",
      "Epoch [80], val_loss: 710.3521\n",
      "Epoch [90], val_loss: 662.6542\n",
      "Epoch [20], val_loss: 665.0139\n",
      "Epoch [40], val_loss: 709.8001\n",
      "Epoch [60], val_loss: 674.8385\n",
      "Epoch [80], val_loss: 688.0225\n",
      "Epoch [90], val_loss: 662.0864\n",
      "Epoch [20], val_loss: 713.5669\n",
      "Epoch [40], val_loss: 705.7086\n",
      "Epoch [60], val_loss: 667.8274\n",
      "Epoch [80], val_loss: 678.8570\n",
      "Epoch [90], val_loss: 703.1265\n",
      "Epoch [20], val_loss: 683.5634\n",
      "Epoch [40], val_loss: 700.8517\n",
      "Epoch [60], val_loss: 668.2949\n",
      "Epoch [80], val_loss: 715.3614\n",
      "Epoch [90], val_loss: 693.1067\n",
      "Epoch [20], val_loss: 672.1299\n",
      "Epoch [40], val_loss: 656.5795\n",
      "Epoch [60], val_loss: 697.6812\n",
      "Epoch [80], val_loss: 653.4412\n",
      "Epoch [90], val_loss: 723.2917\n",
      "Epoch [20], val_loss: 662.3552\n",
      "Epoch [40], val_loss: 672.0490\n",
      "Epoch [60], val_loss: 701.9607\n",
      "Epoch [80], val_loss: 675.0769\n",
      "Epoch [90], val_loss: 708.2873\n",
      "Epoch [20], val_loss: 656.3813\n",
      "Epoch [40], val_loss: 659.7255\n",
      "Epoch [60], val_loss: 652.8754\n",
      "Epoch [80], val_loss: 711.6107\n",
      "Epoch [90], val_loss: 678.5986\n",
      "Epoch [20], val_loss: 696.1342\n",
      "Epoch [40], val_loss: 662.8674\n",
      "Epoch [60], val_loss: 676.1544\n",
      "Epoch [80], val_loss: 715.8352\n",
      "Epoch [90], val_loss: 673.2474\n",
      "Epoch [20], val_loss: 709.7186\n",
      "Epoch [40], val_loss: 708.4524\n",
      "Epoch [60], val_loss: 657.9866\n",
      "Epoch [80], val_loss: 683.6071\n",
      "Epoch [90], val_loss: 670.8909\n",
      "Epoch [20], val_loss: 664.3289\n",
      "Epoch [40], val_loss: 697.4122\n",
      "Epoch [60], val_loss: 659.3744\n",
      "Epoch [80], val_loss: 672.3974\n",
      "Epoch [90], val_loss: 714.1635\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "while i < 50:\n",
    "    epochs = 90\n",
    "    lr = 1e-7\n",
    "    momentum=0.3\n",
    "    history1 = fit(epochs, lr, momentum, model, train_loader, val_loader)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "revised-warren",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20], val_loss: 694.2618\n",
      "Epoch [40], val_loss: 662.2474\n",
      "Epoch [60], val_loss: 691.7355\n",
      "Epoch [70], val_loss: 662.1429\n",
      "Epoch [20], val_loss: 661.6611\n",
      "Epoch [40], val_loss: 688.3156\n",
      "Epoch [60], val_loss: 710.1476\n",
      "Epoch [70], val_loss: 709.6465\n",
      "Epoch [20], val_loss: 661.3975\n",
      "Epoch [40], val_loss: 686.0246\n",
      "Epoch [60], val_loss: 661.7451\n",
      "Epoch [70], val_loss: 708.7631\n",
      "Epoch [20], val_loss: 662.2126\n",
      "Epoch [40], val_loss: 662.2391\n",
      "Epoch [60], val_loss: 662.5270\n",
      "Epoch [70], val_loss: 683.4066\n",
      "Epoch [20], val_loss: 683.3770\n",
      "Epoch [40], val_loss: 683.4886\n",
      "Epoch [60], val_loss: 709.1913\n",
      "Epoch [70], val_loss: 662.3774\n",
      "Epoch [20], val_loss: 709.0323\n",
      "Epoch [40], val_loss: 683.3334\n",
      "Epoch [60], val_loss: 661.6613\n",
      "Epoch [70], val_loss: 683.0842\n",
      "Epoch [20], val_loss: 683.0771\n",
      "Epoch [40], val_loss: 708.0115\n",
      "Epoch [60], val_loss: 707.7217\n",
      "Epoch [70], val_loss: 707.7292\n",
      "Epoch [20], val_loss: 661.8415\n",
      "Epoch [40], val_loss: 663.0531\n",
      "Epoch [60], val_loss: 661.5287\n",
      "Epoch [70], val_loss: 663.5209\n",
      "Epoch [20], val_loss: 707.7312\n",
      "Epoch [40], val_loss: 682.3872\n",
      "Epoch [60], val_loss: 707.7151\n",
      "Epoch [70], val_loss: 707.5628\n",
      "Epoch [20], val_loss: 707.3670\n",
      "Epoch [40], val_loss: 707.4628\n",
      "Epoch [60], val_loss: 663.4063\n",
      "Epoch [70], val_loss: 661.3159\n",
      "Epoch [20], val_loss: 661.4532\n",
      "Epoch [40], val_loss: 707.5886\n",
      "Epoch [60], val_loss: 661.6143\n",
      "Epoch [70], val_loss: 707.7012\n",
      "Epoch [20], val_loss: 664.0426\n",
      "Epoch [40], val_loss: 661.5441\n",
      "Epoch [60], val_loss: 707.7513\n",
      "Epoch [70], val_loss: 707.8007\n",
      "Epoch [20], val_loss: 664.6485\n",
      "Epoch [40], val_loss: 681.1849\n",
      "Epoch [60], val_loss: 681.1019\n",
      "Epoch [70], val_loss: 664.4881\n",
      "Epoch [20], val_loss: 664.8260\n",
      "Epoch [40], val_loss: 707.7858\n",
      "Epoch [60], val_loss: 707.6776\n",
      "Epoch [70], val_loss: 664.6756\n",
      "Epoch [20], val_loss: 680.9698\n",
      "Epoch [40], val_loss: 661.4807\n",
      "Epoch [60], val_loss: 707.6537\n",
      "Epoch [70], val_loss: 661.4330\n",
      "Epoch [20], val_loss: 707.7500\n",
      "Epoch [40], val_loss: 665.6860\n",
      "Epoch [60], val_loss: 665.9783\n",
      "Epoch [70], val_loss: 707.8364\n",
      "Epoch [20], val_loss: 661.3960\n",
      "Epoch [40], val_loss: 707.6660\n",
      "Epoch [60], val_loss: 665.0867\n",
      "Epoch [70], val_loss: 707.3563\n",
      "Epoch [20], val_loss: 707.8519\n",
      "Epoch [40], val_loss: 707.8466\n",
      "Epoch [60], val_loss: 661.4041\n",
      "Epoch [70], val_loss: 707.9764\n",
      "Epoch [20], val_loss: 666.2148\n",
      "Epoch [40], val_loss: 679.3817\n",
      "Epoch [60], val_loss: 665.4103\n",
      "Epoch [70], val_loss: 679.7109\n",
      "Epoch [20], val_loss: 706.9643\n",
      "Epoch [40], val_loss: 665.1501\n",
      "Epoch [60], val_loss: 679.9937\n",
      "Epoch [70], val_loss: 707.1265\n",
      "Epoch [20], val_loss: 665.2401\n",
      "Epoch [40], val_loss: 707.2854\n",
      "Epoch [60], val_loss: 661.1446\n",
      "Epoch [70], val_loss: 680.0558\n",
      "Epoch [20], val_loss: 665.4459\n",
      "Epoch [40], val_loss: 707.0432\n",
      "Epoch [60], val_loss: 661.1285\n",
      "Epoch [70], val_loss: 660.9874\n",
      "Epoch [20], val_loss: 680.0919\n",
      "Epoch [40], val_loss: 661.0786\n",
      "Epoch [60], val_loss: 680.3790\n",
      "Epoch [70], val_loss: 660.8409\n",
      "Epoch [20], val_loss: 661.0687\n",
      "Epoch [40], val_loss: 679.9516\n",
      "Epoch [60], val_loss: 679.8316\n",
      "Epoch [70], val_loss: 679.6158\n",
      "Epoch [20], val_loss: 665.4140\n",
      "Epoch [40], val_loss: 664.9147\n",
      "Epoch [60], val_loss: 679.4572\n",
      "Epoch [70], val_loss: 661.3431\n",
      "Epoch [20], val_loss: 665.3602\n",
      "Epoch [40], val_loss: 661.4650\n",
      "Epoch [60], val_loss: 665.5167\n",
      "Epoch [70], val_loss: 679.6217\n",
      "Epoch [20], val_loss: 706.9515\n",
      "Epoch [40], val_loss: 661.3217\n",
      "Epoch [60], val_loss: 661.3696\n",
      "Epoch [70], val_loss: 679.8795\n",
      "Epoch [20], val_loss: 665.5854\n",
      "Epoch [40], val_loss: 661.5690\n",
      "Epoch [60], val_loss: 661.3600\n",
      "Epoch [70], val_loss: 707.4290\n",
      "Epoch [20], val_loss: 707.5685\n",
      "Epoch [40], val_loss: 707.4807\n",
      "Epoch [60], val_loss: 679.6229\n",
      "Epoch [70], val_loss: 707.5209\n",
      "Epoch [20], val_loss: 665.6144\n",
      "Epoch [40], val_loss: 661.0533\n",
      "Epoch [60], val_loss: 665.6388\n",
      "Epoch [70], val_loss: 660.8727\n",
      "Epoch [20], val_loss: 707.7973\n",
      "Epoch [40], val_loss: 708.0583\n",
      "Epoch [60], val_loss: 679.5147\n",
      "Epoch [70], val_loss: 679.4898\n",
      "Epoch [20], val_loss: 660.6695\n",
      "Epoch [40], val_loss: 707.7939\n",
      "Epoch [60], val_loss: 665.6472\n",
      "Epoch [70], val_loss: 665.3669\n",
      "Epoch [20], val_loss: 665.5778\n",
      "Epoch [40], val_loss: 665.1029\n",
      "Epoch [60], val_loss: 660.4835\n",
      "Epoch [70], val_loss: 665.3294\n",
      "Epoch [20], val_loss: 660.4765\n",
      "Epoch [40], val_loss: 707.9910\n",
      "Epoch [60], val_loss: 665.4565\n",
      "Epoch [70], val_loss: 660.5394\n",
      "Epoch [20], val_loss: 665.3606\n",
      "Epoch [40], val_loss: 707.9641\n",
      "Epoch [60], val_loss: 660.3993\n",
      "Epoch [70], val_loss: 679.3720\n",
      "Epoch [20], val_loss: 660.7810\n",
      "Epoch [40], val_loss: 679.1025\n",
      "Epoch [60], val_loss: 679.1985\n",
      "Epoch [70], val_loss: 660.9862\n",
      "Epoch [20], val_loss: 665.5865\n",
      "Epoch [40], val_loss: 679.1163\n",
      "Epoch [60], val_loss: 665.7208\n",
      "Epoch [70], val_loss: 679.4880\n",
      "Epoch [20], val_loss: 679.3221\n",
      "Epoch [40], val_loss: 707.6755\n",
      "Epoch [60], val_loss: 665.7896\n",
      "Epoch [70], val_loss: 661.0811\n",
      "Epoch [20], val_loss: 665.9860\n",
      "Epoch [40], val_loss: 661.3507\n",
      "Epoch [60], val_loss: 678.7541\n",
      "Epoch [70], val_loss: 707.0012\n",
      "Epoch [20], val_loss: 707.1579\n",
      "Epoch [40], val_loss: 678.7664\n",
      "Epoch [60], val_loss: 666.3142\n",
      "Epoch [70], val_loss: 661.2101\n",
      "Epoch [20], val_loss: 707.2670\n",
      "Epoch [40], val_loss: 665.5901\n",
      "Epoch [60], val_loss: 660.7229\n",
      "Epoch [70], val_loss: 679.3401\n",
      "Epoch [20], val_loss: 707.6073\n",
      "Epoch [40], val_loss: 665.4034\n",
      "Epoch [60], val_loss: 665.7319\n",
      "Epoch [70], val_loss: 707.5009\n",
      "Epoch [20], val_loss: 661.3169\n",
      "Epoch [40], val_loss: 661.4670\n",
      "Epoch [60], val_loss: 679.0891\n",
      "Epoch [70], val_loss: 661.0925\n",
      "Epoch [20], val_loss: 665.9603\n",
      "Epoch [40], val_loss: 707.1244\n",
      "Epoch [60], val_loss: 660.8842\n",
      "Epoch [70], val_loss: 660.9217\n",
      "Epoch [20], val_loss: 665.6318\n",
      "Epoch [40], val_loss: 665.8304\n",
      "Epoch [60], val_loss: 707.0966\n",
      "Epoch [70], val_loss: 679.6184\n",
      "Epoch [20], val_loss: 665.7428\n",
      "Epoch [40], val_loss: 707.4300\n",
      "Epoch [60], val_loss: 665.8704\n",
      "Epoch [70], val_loss: 679.3176\n",
      "Epoch [20], val_loss: 660.7277\n",
      "Epoch [40], val_loss: 665.3521\n",
      "Epoch [60], val_loss: 665.7690\n",
      "Epoch [70], val_loss: 660.7023\n",
      "Epoch [20], val_loss: 665.7061\n",
      "Epoch [40], val_loss: 679.3631\n",
      "Epoch [60], val_loss: 679.3889\n",
      "Epoch [70], val_loss: 707.2785\n",
      "Epoch [20], val_loss: 665.5630\n",
      "Epoch [40], val_loss: 660.9570\n",
      "Epoch [60], val_loss: 660.8572\n",
      "Epoch [70], val_loss: 660.9475\n",
      "Epoch [20], val_loss: 707.5073\n",
      "Epoch [40], val_loss: 660.8388\n",
      "Epoch [60], val_loss: 707.5502\n",
      "Epoch [70], val_loss: 679.8724\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "while i < 50:\n",
    "    epochs = 70\n",
    "    momentum=0.1\n",
    "    lr = 1e-9\n",
    "    history1 = fit(epochs, lr, momentum, model, train_loader, val_loader)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "quarterly-elder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([  3.4100, 150.0000,   2.9000, 166.0000, 249.4000])\n",
      "Target: tensor([18.2160])\n",
      "Prediction: tensor([16.9904])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([16.9904])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Algorithm\n",
    "def validation(input, target, model):\n",
    "    inputs = input.unsqueeze(0)\n",
    "    predictions = model(inputs)\n",
    "    prediction = predictions[0].detach()\n",
    "    print(\"Input:\", input)\n",
    "    print(\"Target:\", target)\n",
    "    print(\"Prediction:\", prediction)\n",
    "    return prediction\n",
    "\n",
    "# Testing the model with some samples\n",
    "input, target = val_ds[0]\n",
    "validation(input, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "future-father",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: tensor([[   3.4100,  150.0000,    2.9000,  166.0000,  249.4000],\n",
      "        [   3.4100,  150.0000,    3.4100,  150.0000,  348.0000],\n",
      "        [   2.9000,  166.0000,    3.4100,  150.0000,  330.6000],\n",
      "        [   3.4100,  150.0000,    2.9000,  166.0000,  530.1200],\n",
      "        [   3.4100,  150.0000,    2.9000,  166.0000,  385.2168],\n",
      "        [   3.4100,  150.0000,    2.9000,  166.0000,  230.6635],\n",
      "        [   3.4100,  150.0000,    2.9000,  166.0000,  570.7200],\n",
      "        [   3.4100,  150.0000,    2.9000,  166.0000,  249.9613],\n",
      "        [   3.4100,  150.0000,    2.9000,  166.0000,  103.2400],\n",
      "        [   3.4100,  150.0000,    3.4100,  150.0000,  146.1600],\n",
      "        [   2.4800,  177.0000,    3.4100,  150.0000,   13.9200],\n",
      "        [   2.9000,  166.0000,    2.9000,  166.0000,   30.1600],\n",
      "        [   3.4100,  150.0000,    2.9000,  166.0000,  369.4434],\n",
      "        [   3.4100,  150.0000,    3.4100,  150.0000, 1316.6000],\n",
      "        [   3.4100,  150.0000,    3.4100,  150.0000,  299.2800],\n",
      "        [   3.4100,  150.0000,    3.4100,  150.0000, 1432.6000],\n",
      "        [   3.4100,  150.0000,    2.9000,  166.0000,  244.7600],\n",
      "        [   3.4100,  150.0000,    2.9000,  166.0000,  301.6000],\n",
      "        [   3.4100,  150.0000,    3.4100,  150.0000,  190.2400],\n",
      "        [   3.4100,  150.0000,    3.4100,  150.0000,  142.6800],\n",
      "        [   3.4100,  150.0000,    2.9000,  166.0000,  462.9181],\n",
      "        [   2.9000,  166.0000,    3.4100,  150.0000,  164.7200],\n",
      "        [   3.4100,  150.0000,    3.4100,  150.0000,  620.6000],\n",
      "        [   3.4100,  150.0000,    3.4100,  150.0000,  405.0525],\n",
      "        [   2.4800,  177.0000,    3.4100,  150.0000,   38.2800],\n",
      "        [   3.4100,  150.0000,    3.4100,  150.0000,  180.9945],\n",
      "        [   3.4100,  150.0000,    2.9000,  166.0000,   54.5200],\n",
      "        [   3.4100,  150.0000,    2.9000,  166.0000,  421.0800],\n",
      "        [   3.4100,  150.0000,    3.4100,  150.0000,   51.3822],\n",
      "        [   2.4800,  177.0000,    3.4100,  150.0000,   77.7200],\n",
      "        [   2.9000,  166.0000,    2.0400,  177.0000,  161.2400],\n",
      "        [   3.4100,  150.0000,    2.9000,  166.0000,  365.9578],\n",
      "        [   3.1000,  182.0000,    2.3600,  177.0000,   84.6800],\n",
      "        [   3.4100,  150.0000,    2.9000,  166.0000,  897.8400],\n",
      "        [   3.4100,  150.0000,    3.4100,  150.0000,  444.2800],\n",
      "        [   3.4100,  150.0000,    3.4100,  150.0000,   63.8000],\n",
      "        [   3.4100,  150.0000,    3.4100,  150.0000,  117.3826],\n",
      "        [   3.4100,  150.0000,    2.9000,  166.0000,  468.6400],\n",
      "        [   3.4100,  150.0000,    3.4100,  150.0000,  146.1600],\n",
      "        [   3.4100,  150.0000,    3.4100,  150.0000,  922.2000],\n",
      "        [   3.4100,  150.0000,    3.4100,  150.0000,  200.6800],\n",
      "        [   3.4100,  150.0000,    2.9000,  166.0000,  229.6800],\n",
      "        [   2.4800,  177.0000,    3.4100,  150.0000,   40.6000],\n",
      "        [   3.4100,  150.0000,    3.4100,  150.0000,  162.4000],\n",
      "        [   2.4800,  177.0000,    3.4100,  150.0000,   54.5200]])\n",
      "Target: tensor([[18.2160],\n",
      "        [21.9780],\n",
      "        [24.7500],\n",
      "        [31.0662],\n",
      "        [20.4208],\n",
      "        [10.8939],\n",
      "        [31.0662],\n",
      "        [18.2255],\n",
      "        [10.3950],\n",
      "        [15.3450],\n",
      "        [ 3.1680],\n",
      "        [ 8.2170],\n",
      "        [20.4208],\n",
      "        [40.5900],\n",
      "        [32.8680],\n",
      "        [43.5600],\n",
      "        [22.3740],\n",
      "        [17.1270],\n",
      "        [22.1760],\n",
      "        [12.7993],\n",
      "        [24.8530],\n",
      "        [ 9.1080],\n",
      "        [30.6900],\n",
      "        [27.3383],\n",
      "        [ 4.7520],\n",
      "        [16.0716],\n",
      "        [ 6.6330],\n",
      "        [26.5320],\n",
      "        [13.3792],\n",
      "        [ 4.9500],\n",
      "        [ 9.5040],\n",
      "        [20.4208],\n",
      "        [ 8.2170],\n",
      "        [34.7941],\n",
      "        [28.4130],\n",
      "        [ 1.6830],\n",
      "        [13.2135],\n",
      "        [19.7010],\n",
      "        [11.5980],\n",
      "        [39.3030],\n",
      "        [18.2160],\n",
      "        [11.1870],\n",
      "        [ 4.6530],\n",
      "        [10.7910],\n",
      "        [ 4.9500]])\n",
      "Prediction: tensor([[17.3475],\n",
      "        [20.5728],\n",
      "        [19.7517],\n",
      "        [28.7859],\n",
      "        [22.1554],\n",
      "        [16.6283],\n",
      "        [30.0988],\n",
      "        [17.3690],\n",
      "        [ 9.8977],\n",
      "        [12.5165],\n",
      "        [ 3.9357],\n",
      "        [ 5.3811],\n",
      "        [21.3799],\n",
      "        [40.9265],\n",
      "        [18.5552],\n",
      "        [42.8415],\n",
      "        [17.1694],\n",
      "        [18.8875],\n",
      "        [15.0358],\n",
      "        [12.2455],\n",
      "        [25.9037],\n",
      "        [13.3280],\n",
      "        [29.4607],\n",
      "        [23.0658],\n",
      "        [ 4.9308],\n",
      "        [14.6781],\n",
      "        [ 6.9382],\n",
      "        [23.9414],\n",
      "        [ 6.3797],\n",
      "        [ 7.0972],\n",
      "        [14.0314],\n",
      "        [21.2111],\n",
      "        [ 8.8431],\n",
      "        [35.8130],\n",
      "        [24.7354],\n",
      "        [ 7.1380],\n",
      "        [10.4544],\n",
      "        [26.1512],\n",
      "        [12.5165],\n",
      "        [34.5893],\n",
      "        [15.4365],\n",
      "        [16.5905],\n",
      "        [ 5.0533],\n",
      "        [13.6481],\n",
      "        [ 5.7884]])\n"
     ]
    }
   ],
   "source": [
    "val_value, target = val_ds[:]\n",
    "predictions = validation(val_value, target, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "phantom-happiness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 164.16x145.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = torch.linspace(0,47,20)\n",
    "b = a\n",
    "fig = plt.figure(figsize=(2.28,2.025))\n",
    "ax = fig.add_axes([0.18, 0.21, 0.76, 0.76])\n",
    "ax.scatter(predictions,target, c='tab:blue', s =26, alpha = 0.6, edgecolors='none')\n",
    "ax.plot(a,b, color='tab:red', alpha = 0.6)\n",
    "ax.tick_params(axis='x', pad=1.2, labelsize= 8)\n",
    "ax.tick_params(axis='y', pad=1.2, labelsize= 8)\n",
    "ax.set_xlabel('Predicted -E (kJ mol$^{-1}$)', fontsize=8)\n",
    "ax.set_ylabel('Actual -E (kJ mol$^{-1}$)', fontsize=8)\n",
    "plt.savefig('modeleva3.png',dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "natural-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Algorithm\n",
    "def predict(values, model):\n",
    "    inputs = values.unsqueeze(0)\n",
    "    predictions = model(inputs)\n",
    "    prediction = predictions[0].detach()\n",
    "    print(\"The input values are:\", inputs)\n",
    "    print(\"The H bond energy is:\", prediction, 'kJ/mol')\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "liable-island",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input values are: tensor([[  2.9000, 166.0000,   2.7400, 204.0000, 145.0000]])\n",
      "The H bond energy is: tensor([13.2756]) kJ/mol\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([13.2756])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = torch.tensor([2.9, 166, 2.74, 204, 145])\n",
    "predict(values, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-edmonton",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
